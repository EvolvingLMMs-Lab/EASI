# EASI

<b>Holistic Evaluation of Multimodal LLMs on Spatial Intelligence</b>

[English](README.md) | ç®€ä½“ä¸­æ–‡

<p align="center">
    <a href="https://arxiv.org/abs/2508.13142" target="_blank">
        <img alt="arXiv" src="https://img.shields.io/badge/arXiv-EASI-red?logo=arxiv" height="20" />
    </a>
    <a href="https://huggingface.co/spaces/lmms-lab-si/EASI-Leaderboard" target="_blank">
        <img alt="Data" src="https://img.shields.io/badge/%F0%9F%A4%97%20_EASI-Leaderboard-ffc107?color=ffc107&logoColor=white" height="20" />
    </a>
    <a href="https://github.com/EvolvingLMMs-Lab/EASI/blob/main/LICENSE"><img src="https://img.shields.io/github/license/EvolvingLMMs-Lab/EASI?style=flat"></a>
</p>

## å¿«é€Ÿäº†è§£ï¼ˆTL;DRï¼‰

- EASI æ˜¯ä¸€ä¸ªé¢å‘å¤šæ¨¡æ€å¤§æ¨¡å‹ç©ºé—´æ™ºèƒ½ï¼ˆSpatial Intelligenceï¼‰çš„ç»Ÿä¸€è¯„æµ‹å¥—ä»¶ã€‚
- EASI æ”¯æŒ**ä¸¤ç§è¯„æµ‹åç«¯**ï¼š[VLMEvalKit](https://github.com/open-compass/VLMEvalKit) å’Œ [lmms-eval](https://github.com/EvolvingLMMs-Lab/lmms-eval)ã€‚
- å®Œæˆå®‰è£…åï¼Œå¯ä»¥ç”¨ä¸‹é¢çš„å‘½ä»¤å¿«é€Ÿè·‘ä¸€ä¸ªç¤ºä¾‹ï¼š

**ä½¿ç”¨ EASI (VLMEvalkit åç«¯)ï¼š**
```bash
cd VLMEvalKit/
python run.py --data MindCubeBench_tiny_raw_qa \
              --model SenseNova-SI-1.3-InternVL3-8B \
              --verbose --reuse --judge extract_matching
```

**ä½¿ç”¨ EASI (LMMs-Eval åç«¯)ï¼š**
```bash
lmms-eval --model qwen2_5_vl \
          --model_args pretrained=sensenova/SenseNova-SI-1.1-Qwen2.5-VL-3B \
          --tasks site_bench_image \
          --batch_size 1 \
          --log_samples \
          --output_path ./logs/
```

## æ¦‚è¿°

EASI æ˜¯ä¸€ä¸ªé¢å‘ç©ºé—´æ™ºèƒ½çš„ç»Ÿä¸€è¯„æµ‹å¥—ä»¶ï¼Œç”¨äºåœ¨ä¸æ–­æ‰©å±•çš„ç©ºé—´åŸºå‡†ä¸Šè¯„ä¼°æœ€å…ˆè¿›çš„é—­æºå’Œå¼€æºå¤šæ¨¡æ€å¤§æ¨¡å‹ã€‚

ä¸»è¦ç‰¹ç‚¹åŒ…æ‹¬ï¼š

- æ”¯æŒè¯„ä¼°**æœ€å…ˆè¿›çš„ç©ºé—´æ™ºèƒ½æ¨¡å‹**ã€‚
- ç³»ç»Ÿæ€§åœ°æ”¶é›†å’Œæ•´åˆ**ä¸æ–­æ¼”è¿›çš„ç©ºé—´æ™ºèƒ½åŸºå‡†æµ‹è¯•**ã€‚
- æä¾›**ä¸¤ç§è¯„æµ‹åç«¯**ï¼Œçµæ´»é€‰æ‹©ï¼š
  - **VLMEvalKit**ï¼šä¸°å¯Œçš„æ¨¡å‹åº“ï¼Œå†…ç½®è¯„åˆ¤åŠŸèƒ½ã€‚
  - **lmms-eval**ï¼šè½»é‡çº§ã€åŸºäº accelerate çš„åˆ†å¸ƒå¼è¯„æµ‹ï¼Œæ”¯æŒå¤§é‡ä»»åŠ¡ã€‚

åœ¨ [v0.1.5](https://github.com/EvolvingLMMs-Lab/EASI/releases/tag/0.1.5) ç‰ˆæœ¬ä¸­ï¼ŒEASI å·²æ”¯æŒ **23 ä¸ªç©ºé—´æ™ºèƒ½æ¨¡å‹** å’Œ **24 ä¸ªç©ºé—´åŸºå‡†æµ‹è¯•**ï¼Œå¹¶å°†æŒç»­æ‰©å±•ã€‚å®Œæ•´çš„æ”¯æŒæ¨¡å‹ä¸åŸºå‡†åˆ—è¡¨è§ ğŸ‘‰ **[Supported Models & Benchmarks](docs/Support_bench_models.md)**ã€‚æ­¤å¤–ï¼ŒEASI è¿˜æä¾›é€æ˜çš„ ğŸ‘‰ **[Benchmark Verification](docs/Benchmark_Verification.md)**ï¼Œæ–¹ä¾¿ä¸å®˜æ–¹è¯„åˆ†è¿›è¡Œå¯¹æ¯”ã€‚

## ğŸ—“ï¸ æœ€æ–°åŠ¨æ€

ğŸŒŸ **[2026-01-09]** [EASI v0.1.5](https://github.com/EvolvingLMMs-Lab/EASI/releases/tag/0.1.5) å‘å¸ƒã€‚ä¸»è¦æ›´æ–°åŒ…æ‹¬ï¼š
- **åŸºå‡†æµ‹è¯•æ”¯æŒæ‰©å±•**: æ–°å¢ STI-Benchã€‚
- **æ¨¡å‹æ”¯æŒæ‰©å±•**ï¼šæ–°å¢ SenseNova-SI-1.1-BAGEL-7B-MoT, SenseNova-SI-1.3-InternVL3-8Bã€‚
- å¢åŠ è¯¦ç»†çš„åŸºå‡†æµ‹è¯•æ•°å€¼å¯¹é½ä¿¡æ¯ **[Benchmark Verification](docs/Benchmark_Verification.md)**


å®Œæ•´å‘ç‰ˆå†å²å’Œè¯¦ç»†æ›´æ–°æ—¥å¿—ï¼Œè¯·å‚è§ ğŸ‘‰ **[Changelog](docs/CHANGELOG.md)**ã€‚

## ğŸ› ï¸ å¿«é€Ÿä¸Šæ‰‹
### å®‰è£…

EASI æä¾›ä¸¤ç§è¯„æµ‹åç«¯ï¼Œæ‚¨å¯ä»¥æ ¹æ®éœ€è¦å®‰è£…å…¶ä¸­ä¸€ä¸ªæˆ–ä¸¤ä¸ªã€‚

#### æ–¹å¼ä¸€ï¼šæœ¬åœ°ç¯å¢ƒï¼ˆVLMEvalKit åç«¯ï¼‰

```bash
git clone --recursive https://github.com/EvolvingLMMs-Lab/EASI.git
cd EASI
pip install -e ./VLMEvalKit
```

#### æ–¹å¼äºŒï¼šæœ¬åœ°ç¯å¢ƒï¼ˆlmms-eval åç«¯ï¼‰

```bash
git clone --recursive https://github.com/EvolvingLMMs-Lab/EASI.git
cd EASI
pip install -e ./lmms-eval spacy
# æ¨èä¾èµ–
# åœ¨ pyproject.toml ä¸­ä½¿ç”¨ "torch==2.7.1", "torchvision==0.22.1"ï¼ˆé€‚ç”¨äºå¤§å¤šæ•°æ¨¡å‹ï¼‰
# å®‰è£… flash-attn ä»¥åŠ é€Ÿæ¨ç†
pip install flash-attn --no-build-isolation
```

#### æ–¹å¼ä¸‰ï¼šåŸºäºDocker

```bash
bash dockerfiles/EASI/build_runtime_docker.sh

docker run --gpus all -it --rm \
  -v /path/to/your/data:/mnt/data \
  --name easi-runtime \
  vlmevalkit_EASI:latest \
  /bin/bash
```

### è¯„æµ‹

EASI æ”¯æŒä¸¤ç§è¯„æµ‹åç«¯ï¼Œè¯·æ ¹æ®æ‚¨çš„éœ€æ±‚é€‰æ‹©åˆé€‚çš„åç«¯ã€‚

---

#### åç«¯ 1ï¼šVLMEvalKit

**é€šç”¨å‘½ä»¤**
```bash
python run.py --data {BENCHMARK_NAME} --model {MODEL_NAME} --judge {JUDGE_MODE} --verbose --reuse
```
è¯·å‚é˜…ä¸‹æ–¹çš„"é…ç½®"éƒ¨åˆ†ï¼ŒæŸ¥çœ‹æ‰€æœ‰å¯ç”¨æ¨¡å‹å’ŒåŸºå‡†æµ‹è¯•çš„å®Œæ•´åˆ—è¡¨ã€‚è¯·å‚é˜… `run.py` æ–‡ä»¶ï¼ŒæŸ¥çœ‹æ‰€æœ‰å‚æ•°çš„å®Œæ•´åˆ—è¡¨ã€‚

**ç¤ºä¾‹**

åœ¨ `MindCubeBench_tiny_raw_qa` ä¸Šè¯„æµ‹ `SenseNova-SI-1.3-InternVL3-8B`ï¼š

```bash
python run.py --data MindCubeBench_tiny_raw_qa \
              --model SenseNova-SI-1.3-InternVL3-8B \
              --verbose --reuse --judge extract_matching
```
è¿™å°†ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¥æå–ç­”æ¡ˆã€‚å¦‚æœæ‚¨æƒ³ä½¿ç”¨åŸºäº LLM çš„è¯„åˆ¤ç³»ç»Ÿï¼ˆä¾‹å¦‚ï¼Œåœ¨è¯„ä¼° SpatialVizBench_CoT æ—¶ï¼‰ï¼Œæ‚¨å¯ä»¥å°†è¯„åˆ¤ç³»ç»Ÿåˆ‡æ¢åˆ° OpenAIï¼š
```bash
export OPENAI_API_KEY=YOUR_KEY
python run.py --data SpatialVizBench_CoT \
              --model {MODEL_NAME} \
              --verbose --reuse --judge gpt-4o-1120
```

---

#### åç«¯ 2ï¼šlmms-eval

lmms-eval æä¾›åŸºäº accelerate çš„åˆ†å¸ƒå¼è¯„æµ‹ï¼Œæ”¯æŒå¤š GPU æ¨ç†ã€‚

**é€šç”¨å‘½ä»¤**
```bash
lmms-eval --model {MODEL_TYPE} \
          --model_args pretrained={MODEL_PATH} \
          --tasks {TASK_NAME} \
          --batch_size 1 \
          --log_samples \
          --output_path ./logs/
```

**ç¤ºä¾‹ï¼šå• GPU**

åœ¨ `site_bench_image` ä¸Šè¯„æµ‹ `Qwen2.5-VL-3B-Instruct`ï¼š

```bash
lmms-eval --model qwen2_5_vl \
          --model_args pretrained=Qwen/Qwen2.5-VL-3B-Instruct \
          --tasks site_bench_image \
          --batch_size 1 \
          --log_samples \
          --output_path ./logs/
```

**ç¤ºä¾‹ï¼šå¤š GPUï¼ˆä½¿ç”¨ accelerateï¼‰**

```bash
CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch \
    --num_processes=4 \
    --num_machines=1 \
    --mixed_precision=no \
    --dynamo_backend=no \
    --main_process_port=12346 \
    -m lmms_eval \
    --model qwen2_5_vl \
    --model_args pretrained=Qwen/Qwen2.5-VL-3B-Instruct,attn_implementation=flash_attention_2 \
    --tasks site_bench_image \
    --batch_size 1 \
    --log_samples \
    --output_path ./logs/
```

**åˆ—å‡ºæ‰€æœ‰å¯ç”¨ä»»åŠ¡**
```bash
lmms-eval --tasks list
```

æ›´å¤š lmms-eval ä½¿ç”¨è¯¦æƒ…ï¼Œè¯·å‚é˜… [lmms-eval/docs/](lmms-eval/docs/) ä¸­çš„æ–‡æ¡£ï¼ŒåŒ…æ‹¬ [æ¨¡å‹æŒ‡å—](lmms-eval/docs/model_guide.md)ã€[ä»»åŠ¡æŒ‡å—](lmms-eval/docs/task_guide.md) å’Œ [è¿è¡Œç¤ºä¾‹](lmms-eval/docs/run_examples.md)ã€‚

---

### é…ç½®

#### EASI (VLMEvalkit åç«¯) é…ç½®

**VLM é…ç½®**ï¼šæ‰€æœ‰ VLM éƒ½åœ¨ `vlmeval/config.py` ä¸­é…ç½®ã€‚åœ¨è¯„æµ‹æ—¶ï¼Œä½ åº”å½“ä½¿ç”¨è¯¥æ–‡ä»¶ä¸­ supported_VLM æŒ‡å®šçš„æ¨¡å‹åç§°æ¥é€‰æ‹© VLMã€‚å¼€å§‹è¯„æµ‹å‰ï¼Œè¯·å…ˆé€šè¿‡å¦‚ä¸‹å‘½ä»¤ç¡®è®¤è¯¥ VLM å¯ä»¥æˆåŠŸæ¨ç†ï¼š`vlmutil check {MODEL_NAME}`ã€‚

**åŸºå‡†ï¼ˆBenchmarkï¼‰é…ç½®**ï¼šå®Œæ•´çš„å·²æ”¯æŒåŸºå‡†åˆ—è¡¨è§ VLMEvalKit å®˜æ–¹æ–‡æ¡£ [VLMEvalKit Supported Benchmarks](https://aicarrier.feishu.cn/wiki/Qp7wwSzQ9iK1Y6kNUJVcr6zTnPe?table=tblsdEpLieDoCxtb&view=vewa8sGZrY)ã€‚å¯¹äº [EASI Leaderboard](https://huggingface.co/spaces/lmms-lab-si/easi-leaderboard)ï¼Œæ‰€æœ‰ EASI åŸºå‡†æµ‹è¯•åŠå…¶å¯¹åº”çš„ --data åç§°æ±‡æ€»åœ¨ [æ”¯æŒçš„æ¨¡å‹å’ŒåŸºå‡†æµ‹è¯•](docs/Support_bench_models.md) ä¸­ã€‚


#### EASI (lmms-eval åç«¯) é…ç½®

**æ¨¡å‹é…ç½®**ï¼šlmms-eval æ”¯æŒå¤šç§æ¨¡å‹ç±»å‹ï¼ŒåŒ…æ‹¬ `qwen2_5_vl`ã€`llava`ã€`internvl2` ç­‰ã€‚ä½¿ç”¨ `--model_args` æŒ‡å®šæ¨¡å‹å‚æ•°ï¼Œå¦‚ `pretrained`ã€`attn_implementation` ç­‰ã€‚

**ä»»åŠ¡é…ç½®**ï¼šä»»åŠ¡å®šä¹‰åœ¨ `lmms-eval/lmms_eval/tasks/` ç›®å½•ä¸‹ã€‚åˆ—å‡ºæ‰€æœ‰å¯ç”¨ä»»åŠ¡ï¼š
```bash
lmms-eval --tasks list
```

ç©ºé—´æ™ºèƒ½è¯„æµ‹çš„ç¤ºä¾‹ä»»åŠ¡ï¼š
| ä»»åŠ¡åç§° | æè¿° |
|-----------|-------------|
| `site_bench_image` | SITE-Bench å›¾åƒè¯„æµ‹ |
| `site_bench_video` | SITE-Bench è§†é¢‘è¯„æµ‹ |

æ›´å¤š lmms-eval ä½¿ç”¨è¯¦æƒ…ï¼Œè¯·å‚é˜… [lmms-eval æ–‡æ¡£](lmms-eval/README.md)ã€‚

### æäº¤

å°†æ‚¨çš„è¯„æµ‹ç»“æœæäº¤åˆ°æˆ‘ä»¬çš„ [EASI Leaderboard](https://huggingface.co/spaces/lmms-lab-si/easi-leaderboard)ï¼š

1. è®¿é—® [EASI Leaderboard](https://huggingface.co/spaces/lmms-lab-si/easi-leaderboard) é¡µé¢ã€‚
2. ç‚¹å‡» **ğŸš€ Submit here!** è¿›å…¥æäº¤è¡¨å•ã€‚
3. æŒ‰ç…§é¡µé¢ä¸Šçš„è¯´æ˜å¡«å†™æäº¤è¡¨å•ï¼Œå¹¶æäº¤ä½ çš„ç»“æœã€‚

## ğŸ–Šï¸ å¼•ç”¨

```bib
@article{easi2025,
  title={Holistic Evaluation of Multimodal LLMs on Spatial Intelligence},
  author={Cai, Zhongang and Wang, Yubo and Sun, Qingping and Wang, Ruisi and Gu, Chenyang and Yin, Wanqi and Lin, Zhiqian and Yang, Zhitao and Wei, Chen and Shi, Xuanke and Deng, Kewang and Han, Xiaoyang and Chen, Zukai and Li, Jiaqi and Fan, Xiangyu and Deng, Hanming and Lu, Lewei and Li, Bo and Liu, Ziwei and Wang, Quan and Lin, Dahua and Yang, Lei},
  journal={arXiv preprint arXiv:2508.13142},
  year={2025}
}
```
